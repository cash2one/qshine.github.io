<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>scrapy-redis总结 | qshine</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">scrapy-redis总结</h1><a id="logo" href="/.">qshine</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">scrapy-redis总结</h1><div class="post-meta">Nov 8, 2017<span> | </span><span class="category"><a href="/categories/爬虫/">爬虫</a></span></div><div class="post-content"><h2 id="queue-py"><a href="#queue-py" class="headerlink" title="queue.py"></a>queue.py</h2><p>scrapy-redis中有三个队列, 三个队列都继承自<code>Base</code>类</p>
<h4 id="1-先进先出-FIFO"><a href="#1-先进先出-FIFO" class="headerlink" title="1. 先进先出: FIFO"></a>1. 先进先出: FIFO</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">FifoQueue</span><span class="params">(Base)</span>:</span></div><div class="line">    <span class="string">"""Per-spider FIFO queue"""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the queue"""</span></div><div class="line">        <span class="keyword">return</span> self.server.llen(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        self.server.lpush(self.key, self._encode_request(request))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""Pop a request"""</span></div><div class="line">        <span class="keyword">if</span> timeout &gt; <span class="number">0</span>:</div><div class="line">            data = self.server.brpop(self.key, timeout)</div><div class="line">            <span class="keyword">if</span> isinstance(data, tuple):</div><div class="line">                data = data[<span class="number">1</span>]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            data = self.server.rpop(self.key)</div><div class="line">        <span class="keyword">if</span> data:</div><div class="line">            <span class="keyword">return</span> self._decode_request(data)</div></pre></td></tr></table></figure>
<p>使用了redis的list结构</p>
<h4 id="2-优先级队列-PriorityQueue"><a href="#2-优先级队列-PriorityQueue" class="headerlink" title="2. 优先级队列: PriorityQueue"></a>2. 优先级队列: PriorityQueue</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PriorityQueue</span><span class="params">(Base)</span>:</span></div><div class="line">    <span class="string">"""Per-spider priority queue abstraction using redis' sorted set"""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the queue"""</span></div><div class="line">        <span class="keyword">return</span> self.server.zcard(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        data = self._encode_request(request)</div><div class="line">        score = -request.priority</div><div class="line">        <span class="comment"># We don't use zadd method as the order of arguments change depending on</span></div><div class="line">        <span class="comment"># whether the class is Redis or StrictRedis, and the option of using</span></div><div class="line">        <span class="comment"># kwargs only accepts strings, not bytes.</span></div><div class="line">        self.server.execute_command(<span class="string">'ZADD'</span>, self.key, score, data)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line"><span class="string">        Pop a request</span></div><div class="line"><span class="string">        timeout not support in this queue class</span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="comment"># use atomic range/remove using multi/exec</span></div><div class="line">        pipe = self.server.pipeline()</div><div class="line">        pipe.multi()</div><div class="line">        pipe.zrange(self.key, <span class="number">0</span>, <span class="number">0</span>).zremrangebyrank(self.key, <span class="number">0</span>, <span class="number">0</span>)</div><div class="line">        results, count = pipe.execute()</div><div class="line">        <span class="keyword">if</span> results:</div><div class="line">            <span class="keyword">return</span> self._decode_request(results[<span class="number">0</span>])</div></pre></td></tr></table></figure>
<p>使用redis的<code>sorted set</code>实现, 如果在spider脚本中需要指定<code>priority</code>的话, 一定要在<code>settings</code>中来声明使用的是<code>PriorityQueue</code>,<br>取相反数后高优先级的就会排在最前面</p>
<h4 id="3-后进先出-栈"><a href="#3-后进先出-栈" class="headerlink" title="3. 后进先出(栈)"></a>3. 后进先出(栈)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LifoQueue</span><span class="params">(Base)</span>:</span></div><div class="line">    <span class="string">"""Per-spider LIFO queue."""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the stack"""</span></div><div class="line">        <span class="keyword">return</span> self.server.llen(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        self.server.lpush(self.key, self._encode_request(request))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""Pop a request"""</span></div><div class="line">        <span class="keyword">if</span> timeout &gt; <span class="number">0</span>:</div><div class="line">            data = self.server.blpop(self.key, timeout)</div><div class="line">            <span class="keyword">if</span> isinstance(data, tuple):</div><div class="line">                data = data[<span class="number">1</span>]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            data = self.server.lpop(self.key)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> data:</div><div class="line">            <span class="keyword">return</span> self._decode_request(data)</div></pre></td></tr></table></figure>
<p>和先进先出队列基本一样, 实现了栈结构</p>
<h2 id="2-dupefilter-py"><a href="#2-dupefilter-py" class="headerlink" title="2. dupefilter.py"></a>2. dupefilter.py</h2><p>scrapy原生使用了一个python的<code>set</code>结构来进行请求去重, 在scrapy-redis中使用redis的<code>集合(set)</code>进行了替换, 指纹的计算方法还是用的原生的, 及如果之前请求过返回0, 否则返回1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_seen</span><span class="params">(self, request)</span>:</span></div><div class="line">    <span class="string">"""Returns True if request was already seen.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    request : scrapy.http.Request</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    bool</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line">    fp = self.request_fingerprint(request)    <span class="comment"># 得到请求的指纹</span></div><div class="line">    <span class="comment"># This returns the number of values added, zero if already exists.</span></div><div class="line">    added = self.server.sadd(self.key, fp)    <span class="comment"># 把指纹添加到redis的集合中</span></div><div class="line">    <span class="keyword">return</span> added == <span class="number">0</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_fingerprint</span><span class="params">(self, request)</span>:</span></div><div class="line">    <span class="string">"""Returns a fingerprint for a given request.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    request : scrapy.http.Request</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    str</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="keyword">return</span> request_fingerprint(request)    <span class="comment"># 得到请求指纹</span></div></pre></td></tr></table></figure>
<p>请求指纹计算使用的是<strong>sha1</strong>算法, 计算值包括请求方法, url, body等信息</p>
<h2 id="scheduler-py"><a href="#scheduler-py" class="headerlink" title="scheduler.py"></a>scheduler.py</h2><p>调度器肯定要和<code>请求队列</code>和<code>去重队列</code>进行交互, 所以初始化要获取使用的<code>queue</code>和<code>dupfilter</code>的类, 并在<code>open</code>方法中完成实例化</p>
<h4 id="open方法"><a href="#open方法" class="headerlink" title="open方法"></a>open方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self, spider)</span>:</span></div><div class="line">    self.spider = spider</div><div class="line"></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="comment"># 得到队列queue的实例化对象</span></div><div class="line">        self.queue = load_object(self.queue_cls)(</div><div class="line">            server=self.server,</div><div class="line">            spider=spider,</div><div class="line">            key=self.queue_key % &#123;<span class="string">'spider'</span>: spider.name&#125;,</div><div class="line">            serializer=self.serializer,</div><div class="line">        )</div><div class="line">    <span class="keyword">except</span> TypeError <span class="keyword">as</span> e:</div><div class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Failed to instantiate queue class '%s': %s"</span>,</div><div class="line">                         self.queue_cls, e)</div><div class="line"></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="comment"># 得到去重的实例化对象</span></div><div class="line">        self.df = load_object(self.dupefilter_cls)(</div><div class="line">            server=self.server,</div><div class="line">            key=self.dupefilter_key % &#123;<span class="string">'spider'</span>: spider.name&#125;,</div><div class="line">            debug=spider.settings.getbool(<span class="string">'DUPEFILTER_DEBUG'</span>),</div><div class="line">        )</div><div class="line">    <span class="keyword">except</span> TypeError <span class="keyword">as</span> e:</div><div class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Failed to instantiate dupefilter class '%s': %s"</span>,</div><div class="line">                         self.dupefilter_cls, e)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> self.flush_on_start:    <span class="comment"># 如果为True, 要在爬虫开启前删除对应爬虫request队列和dupfilter队列</span></div><div class="line">        self.flush()</div><div class="line">    <span class="comment"># notice if there are requests already in the queue to resume the crawl</span></div><div class="line">    <span class="keyword">if</span> len(self.queue):</div><div class="line">        spider.log(<span class="string">"Resuming crawl (%d requests scheduled)"</span> % len(self.queue))</div></pre></td></tr></table></figure>
<h4 id="close方法"><a href="#close方法" class="headerlink" title="close方法"></a>close方法</h4><p>如果在<code>settings</code>中设置<code>SCHEDULER_PERSIST = True</code>, 则不会执行删除(flush)操作, 否则在爬虫关闭时会删除爬虫的<code>request</code>和<code>dupfilter</code>队列</p>
<h4 id="其它方法"><a href="#其它方法" class="headerlink" title="其它方法"></a>其它方法</h4><ul>
<li>enqueue_request: 入队操作, 先判断是否要过滤及是否抓取过</li>
<li>next_request: 弹出任务去执行</li>
</ul>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>在settings中有个配置<code>SCHEDULER_PERSIST</code>, 默认是<code>False</code>的, 就是每次关闭爬虫的时候都会删除<code>去重集合</code>和<code>请求队列</code>, 所以如果要求爬虫能够暂停和恢复的话要设置为True</p>
<h3 id="spider-py"><a href="#spider-py" class="headerlink" title="spider.py"></a>spider.py</h3><p>scrapy有<code>Spider</code>和<code>CrawlerSpider</code>, 这里只看scrapy-redis中的<code>RedisSpider</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</div><div class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DontCloseSpider</div><div class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> Spider, CrawlSpider</div><div class="line"></div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> connection, defaults</div><div class="line"><span class="keyword">from</span> .utils <span class="keyword">import</span> bytes_to_str</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisMixin</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""Mixin class to implement reading urls from a redis queue."""</span></div><div class="line">    redis_key = <span class="keyword">None</span></div><div class="line">    redis_batch_size = <span class="keyword">None</span></div><div class="line">    redis_encoding = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="comment"># Redis client placeholder.</span></div><div class="line">    server = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Returns a batch of start requests from redis."""</span></div><div class="line">        <span class="keyword">return</span> self.next_requests()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_redis</span><span class="params">(self, crawler=None)</span>:</span></div><div class="line">        <span class="string">"""Setup redis connection and idle signal.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        This should be called after the spider has set its crawler object.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">if</span> self.server <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="comment"># We allow optional crawler argument to keep backwards</span></div><div class="line">            <span class="comment"># compatibility.</span></div><div class="line">            <span class="comment"># <span class="doctag">XXX:</span> Raise a deprecation warning.</span></div><div class="line">            crawler = getattr(self, <span class="string">'crawler'</span>, <span class="keyword">None</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"crawler is required"</span>)</div><div class="line"></div><div class="line">        settings = crawler.settings</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.redis_key <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            self.redis_key = settings.get(</div><div class="line">                <span class="string">'REDIS_START_URLS_KEY'</span>, defaults.START_URLS_KEY,</div><div class="line">            )</div><div class="line"></div><div class="line">        <span class="comment"># 得到redis的start_urls key</span></div><div class="line">        self.redis_key = self.redis_key % &#123;<span class="string">'name'</span>: self.name&#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.redis_key.strip():</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"redis_key must not be empty"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># 获取并发数量</span></div><div class="line">        <span class="keyword">if</span> self.redis_batch_size <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Deprecate this setting (REDIS_START_URLS_BATCH_SIZE).</span></div><div class="line">            self.redis_batch_size = settings.getint(</div><div class="line">                <span class="string">'REDIS_START_URLS_BATCH_SIZE'</span>,</div><div class="line">                settings.getint(<span class="string">'CONCURRENT_REQUESTS'</span>),</div><div class="line">            )</div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            self.redis_batch_size = int(self.redis_batch_size)</div><div class="line">        <span class="keyword">except</span> (TypeError, ValueError):</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"redis_batch_size must be an integer"</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.redis_encoding <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            self.redis_encoding = settings.get(<span class="string">'REDIS_ENCODING'</span>, defaults.REDIS_ENCODING)</div><div class="line"></div><div class="line">        self.logger.info(<span class="string">"Reading start URLs from redis key '%(redis_key)s' "</span></div><div class="line">                         <span class="string">"(batch size: %(redis_batch_size)s, encoding: %(redis_encoding)s"</span>,</div><div class="line">                         self.__dict__)</div><div class="line"></div><div class="line">        <span class="comment"># 返回redis连接的实例</span></div><div class="line">        self.server = connection.from_settings(crawler.settings)</div><div class="line">        <span class="comment"># The idle signal is called when the spider has no requests left,</span></div><div class="line">        <span class="comment"># that's when we will schedule new requests from redis queue</span></div><div class="line">        crawler.signals.connect(self.spider_idle, signal=signals.spider_idle)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Returns a request to be scheduled or none."""</span></div><div class="line">        <span class="comment"># 从 start_urls 中获取任务进行爬取</span></div><div class="line">        use_set = self.settings.getbool(<span class="string">'REDIS_START_URLS_AS_SET'</span>, defaults.START_URLS_AS_SET)</div><div class="line">        fetch_one = self.server.spop <span class="keyword">if</span> use_set <span class="keyword">else</span> self.server.lpop</div><div class="line">        <span class="comment"># <span class="doctag">XXX:</span> Do we need to use a timeout here?</span></div><div class="line">        found = <span class="number">0</span></div><div class="line">        <span class="comment"># <span class="doctag">TODO:</span> Use redis pipeline execution.</span></div><div class="line">        <span class="keyword">while</span> found &lt; self.redis_batch_size:</div><div class="line">            data = fetch_one(self.redis_key)</div><div class="line">            <span class="keyword">if</span> <span class="keyword">not</span> data:</div><div class="line">                <span class="comment"># Queue empty.</span></div><div class="line">                <span class="keyword">break</span></div><div class="line">            req = self.make_request_from_data(data)    <span class="comment"># 构造请求</span></div><div class="line">            <span class="keyword">if</span> req:</div><div class="line">                <span class="keyword">yield</span> req</div><div class="line">                found += <span class="number">1</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                self.logger.debug(<span class="string">"Request not made from data: %r"</span>, data)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> found:</div><div class="line">            self.logger.debug(<span class="string">"Read %s requests from '%s'"</span>, found, self.redis_key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_request_from_data</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="string">"""Returns a Request instance from data coming from Redis.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        By default, ``data`` is an encoded URL. You can override this method to</span></div><div class="line"><span class="string">        provide your own message decoding.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        data : bytes</span></div><div class="line"><span class="string">            Message from redis.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        url = bytes_to_str(data, self.redis_encoding)</div><div class="line">        <span class="keyword">return</span> self.make_requests_from_url(url)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">schedule_next_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Schedules a request if available"""</span></div><div class="line">        <span class="comment"># <span class="doctag">TODO:</span> While there is capacity, schedule a batch of redis requests.</span></div><div class="line">        <span class="keyword">for</span> req <span class="keyword">in</span> self.next_requests():</div><div class="line">            self.crawler.engine.crawl(req, spider=self)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_idle</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Schedules a request if available, otherwise waits."""</span></div><div class="line">        <span class="comment"># <span class="doctag">XXX:</span> Handle a sentinel to close the spider.</span></div><div class="line">        self.schedule_next_requests()</div><div class="line">        <span class="keyword">raise</span> DontCloseSpider</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisSpider</span><span class="params">(RedisMixin, Spider)</span>:</span></div><div class="line">    <span class="string">"""Spider that reads urls from redis queue when idle.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Attributes</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    redis_key : str (default: REDIS_START_URLS_KEY)</span></div><div class="line"><span class="string">        Redis key where to fetch start URLs from..</span></div><div class="line"><span class="string">    redis_batch_size : int (default: CONCURRENT_REQUESTS)</span></div><div class="line"><span class="string">        Number of messages to fetch from redis on each attempt.</span></div><div class="line"><span class="string">    redis_encoding : str (default: REDIS_ENCODING)</span></div><div class="line"><span class="string">        Encoding to use when decoding messages from redis queue.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Settings</span></div><div class="line"><span class="string">    --------</span></div><div class="line"><span class="string">    REDIS_START_URLS_KEY : str (default: "&lt;spider.name&gt;:start_urls")</span></div><div class="line"><span class="string">        Default Redis key where to fetch start URLs from..</span></div><div class="line"><span class="string">    REDIS_START_URLS_BATCH_SIZE : int (deprecated by CONCURRENT_REQUESTS)</span></div><div class="line"><span class="string">        Default number of messages to fetch from redis on each attempt.</span></div><div class="line"><span class="string">    REDIS_START_URLS_AS_SET : bool (default: False)</span></div><div class="line"><span class="string">        Use SET operations to retrieve messages from the redis queue. If False,</span></div><div class="line"><span class="string">        the messages are retrieve using the LPOP command.</span></div><div class="line"><span class="string">    REDIS_ENCODING : str (default: "utf-8")</span></div><div class="line"><span class="string">        Default encoding to use when decoding messages from redis queue.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(self, crawler, *args, **kwargs)</span>:</span></div><div class="line">        obj = super(RedisSpider, self).from_crawler(crawler, *args, **kwargs)    <span class="comment"># 调用Spider类中的方法, 配置close signal</span></div><div class="line">        obj.setup_redis(crawler)    <span class="comment"># RedisSpider中初始化redis的连接</span></div><div class="line">        <span class="keyword">return</span> obj</div></pre></td></tr></table></figure></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>工作中经常用到<code>scrapy-redis</code>来进行抓取, 也会有很多情况处理起来比较复杂的情况, 比如之前碰到过一个网站一开始就是post请求的方式, 当时的解决方案是把post的参数放到url中, 然后把整个url扔到start_urls队列, 在下载器中间件拦截住连接, 然后再改为post形式, 最后正常工作了. </p>
</div><div class="tags"><a href="/tags/scrapy/">scrapy</a><a href="/tags/scrapy-redis/">scrapy-redis</a></div><div class="post-nav"><a href="/2017/11/02/select-poll-epoll/" class="next">select/poll/epoll学习笔记</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web后端/">Web后端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/web框架/">web框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安全/">安全</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构和算法/">数据结构和算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/设计模式/">设计模式</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/tornado/" style="font-size: 15px;">tornado</a> <a href="/tags/安全/" style="font-size: 15px;">安全</a> <a href="/tags/Django/" style="font-size: 15px;">Django</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/pyspider/" style="font-size: 15px;">pyspider</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/python开发环境/" style="font-size: 15px;">python开发环境</a> <a href="/tags/python模块/" style="font-size: 15px;">python模块</a> <a href="/tags/scrapy/" style="font-size: 15px;">scrapy</a> <a href="/tags/scrapy-redis/" style="font-size: 15px;">scrapy-redis</a> <a href="/tags/操作系统/" style="font-size: 15px;">操作系统</a> <a href="/tags/supervisor/" style="font-size: 15px;">supervisor</a> <a href="/tags/数据结构和算法/" style="font-size: 15px;">数据结构和算法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/11/08/scrapy-redis总结/">scrapy-redis总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/02/select-poll-epoll/">select/poll/epoll学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/01/B和B-树/">B和B+树</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/01/布隆过滤器/">布隆过滤器</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/23/Docker-四-数据卷/">Docker(四)数据卷</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/22/图的构造和遍历/">图的构造和遍历</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/18/Django使用已存在表/">Django使用已存在表</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/16/二叉堆/">二叉堆</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/25/python静态方法和类方法/">python静态方法和类方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/20/CentOS7安装MySQL/">CentOS7安装MySQL</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2017 <a href="/." rel="nofollow">qshine.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>